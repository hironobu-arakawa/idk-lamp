# decision-closure

**Decision Closure Structure**  
— 用途未定義世界における「判断を確定させてよいか」を扱う構造モデル

---

## この README の役割

この README は、  
判断閉路構造（Decision Closure Structure）の**入口と境界**を示すためのものです。

- 構造の完全な定義  
- 各ステップの詳細  
- 途中反転や idk-lamp の厳密な説明  

は、README では扱いません。

本構造を追体験したい場合は、  
**必ず docs/00_overview.ja.md から読み進めてください。**

---

## これは何か

このリポジトリは、  
**AIの出力を「そのまま判断として確定させてよいか」**  
を扱うための**構造（Structure）**を整理・研究するものです。

- AIの精度を上げる話ではありません  
- 倫理・安全・注意喚起を主張するものでもありません  
- UIや発話表現を定義するものでもありません  

扱うのは、次の一点だけです。

> **この出力で、判断を確定させてよいのか？**

---

## なぜこの問題が生じるのか

対話型AIは、「用途」を観測できません。

しかし現実では、AIの出力は、

- 参考情報として使われることも  
- 行動の根拠として使われることも  
- 誰かの判断を代替してしまうこともあります  

用途が定義されていない以上、  
**同じ出力が、どの段階で使われるかは途中で変わります**。

そのため用途未定義世界では、

> **AIは「判断してよいか」を一度決めて終わりにできない**

という状態が常に発生します。

---

## 判断が「確定してしまう」という問題

対話型AIは内省できません。

そのため、

- 判断してはいけない場面で  
- 出力がそのまま判断として使われ  
- 結果的に判断が確定してしまう  

という問題が起きます。

本リポジトリでは、  
この **「判断が確定してしまう現象」** を次のように呼びます。

> **判断が閉じる（Decision Closure）**

---

## 判断閉路構造が扱うもの／扱わないもの

### 扱うもの

- 判断を **AIが確定させてよいか**
- その可否を **構造として決めること**

### 扱わないもの

- 判断内容の正しさ  
- 出力の精度  
- 倫理的妥当性  
- UI・表現・トーン設計  

---

## 用途が決まっている世界との違い

用途が明確に定義されているシステムでは、

- 目的が定まっており  
- 使われ方が限定され  
- 責任主体が合意されています  

この場合、  
判断は **免責や契約** によって処理できます。

Decision Closure が扱うのは、  
**この前提が成立しない世界だけ**です。

---

## なぜ「構造」なのか

用途未定義世界では、

- 誰が責任を持つか  
- どこまで正確である必要があるか  
- その判断がどこで使われるか  

を、AI内部で確定できません。

それにもかかわらず、  
判断を閉じるかどうか自体は決めなければならない。

この判定を  
人の善意・注意・運用に委ねると、  
**必ず無自覚な判断確定が起きます**。

そのため、

> 判断を確定させてよいかは、  
> 人や運用ではなく、  
> **構造として外在化されていなければならない**

という結論に至ります。

---

## この先の内容について

判断閉路構造では、

- 人間の判断を5つの軸に分解し  
- その値を使わず  
- 危険側に倒れた瞬間だけを抽象化し  
- 判断を閉じるかどうかを決めます  

また、対話途中で判断の性質が変わる  
**途中反転（Transition）** や、  
閉じられない状態を示す **idk-lamp** も  
この構造の中で位置づけられます。

これらの詳細は、README では扱いません。

---

## 次に読むべきもの

判断閉路構造の全体像と内部論理は、  
以下のドキュメントにまとめています。

→ **docs/00_overview.ja.md**

---

## ステータス

- 状態：**Under Research**  
- 構造：暫定確定（破綻確認済み）  
- UI / 実装：対象外  

---

## 最後に

このリポジトリが扱っているのは、  
**AIが「分からないから黙る」のではなく、  
「確定してはいけないから確定しない」ための構造**です。

判断を止める理由を、  
感情や倫理ではなく、  
**構造として残すこと**。

それが、このリポジトリの目的です。

---

## Context

このプロジェクトは、AIが判断を止め、
人間の責任へと委ねるべき境界を可視化するための
実践的なシグナルとして設計されています。

- idk-lamp（公式サイト）  
  https://idk-lamp.org/ja

この取り組みは、AI支援システムにおける
設計・責任・境界のあり方を探究する
設計思想 VCDesign から生まれました。

- VCDesign  
  https://vcdesign.org/ja

本リポジトリは単体でも利用・理解できます。  
事前知識は必要ありません。
